{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sinhajiya/DSE318-NLP-Assignment-Solutions/blob/main/Assignment2/22161_jiyasinha_nlpassignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQG7XB_AmoIn"
      },
      "source": [
        "## IMPORTING LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCHjQEZQmqOK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import randint, sample, seed, choice\n",
        "import tensorflow as tf\n",
        "import re\n",
        "from collections import Counter\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils.class_weight import compute_class_weight\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URSlBvqvRNP0",
        "outputId": "608cc96b-29e1-4b55-bc54-d007fc2a60b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('GPU device not found')\n",
        "else:\n",
        "  print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fvNQ6odmlns"
      },
      "source": [
        "## LOADING DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jk9Zbtj3mERg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "928a57c3-ab7b-44ba-9ad9-e40042937a94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Assignment_1_2025' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/islnlp/Assignment_1_2025"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YusdjrNyYEe0",
        "outputId": "cf7f6819-9d8b-4e58-d35f-fcf729e04c23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DSE318-NLP-Assignment-Solutions'...\n",
            "remote: Enumerating objects: 127, done.\u001b[K\n",
            "remote: Total 127 (delta 0), reused 0 (delta 0), pack-reused 127 (from 2)\u001b[K\n",
            "Receiving objects: 100% (127/127), 149.64 MiB | 13.55 MiB/s, done.\n",
            "Resolving deltas: 100% (25/25), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/sinhajiya/DSE318-NLP-Assignment-Solutions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pull():\n",
        "  %cd DSE318-NLP-Assignment-Solutions/\n",
        "  !git pull origin main\n",
        "  %cd .."
      ],
      "metadata": {
        "id": "3rR-bNzq-u9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoCGMiUqmYQg"
      },
      "outputs": [],
      "source": [
        "def load_data(name):\n",
        "  root_fp = f\"/content/Assignment_1_2025/{name}\"\n",
        "  train = pd.read_csv(os.path.join(root_fp, \"train.csv\"))\n",
        "  val = pd.read_csv(os.path.join(root_fp, \"val.csv\"))\n",
        "  train = train.dropna(subset=['Sentence'])\n",
        "  val = val.dropna(subset=['Sentence'])\n",
        "  return train, val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LX4iA9aPmax3"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(Sentence):\n",
        "\n",
        "  # Preprocessing steps:\n",
        "  # 1. All lower case characters\n",
        "  # 2. URL removal\n",
        "  # 3. Multiple dots to single dot\n",
        "  # 4. Extra spaces to single space\n",
        "  # 5. Removes non-alphabetic chars\n",
        "\n",
        "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*(),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
        "    Sentence = Sentence.lower()\n",
        "    Sentence = re.sub(url_pattern, \"\", Sentence)\n",
        "    Sentence = re.sub(r\"\\.{2,}\", \".\", Sentence)\n",
        "    Sentence = re.sub(r\"\\s+\", \" \", Sentence).strip()\n",
        "    Sentence = re.sub(r\"[^a-zA-Z\\s]\", \"\", Sentence)\n",
        "    return Sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bg15__OwmgH9"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_data(name):\n",
        "\n",
        "  train, val = load_data(name)\n",
        "  train[\"Sentence_preprocessed\"] = train[\"Sentence\"].astype(str).apply(preprocess_text)\n",
        "  val[\"Sentence_preprocessed\"] = val[\"Sentence\"].astype(str).apply(preprocess_text)\n",
        "\n",
        "  return train, val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCMTMEAzmyt-"
      },
      "outputs": [],
      "source": [
        "def form_vocab(data,isdataframe=True):\n",
        "\n",
        "  vocab_size = 0\n",
        "  vocab = set()\n",
        "  word2index = dict()  # Gives mapping from index to word\n",
        "  index2word = dict()  # Gives mapping of word to index\n",
        "\n",
        "  if isdataframe:\n",
        "    data = data[\"Sentence_preprocessed\"]\n",
        "\n",
        "  for sentence in data:\n",
        "    for word in sentence.split():\n",
        "      if word not in word2index:\n",
        "        word2index[word] = vocab_size\n",
        "        index2word[vocab_size] = word\n",
        "        vocab.add(word)\n",
        "        vocab_size += 1\n",
        "  print(f\"Vocabulary of {vocab_size} created\")\n",
        "  return vocab, vocab_size, word2index, index2word\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcXrCvxu23Wz"
      },
      "source": [
        "## WORD2VEC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73fYUFZE05G0"
      },
      "outputs": [],
      "source": [
        "def skip_gram(data, window_size,k=5, isdataframe=True):\n",
        "\n",
        "  seed(42)\n",
        "  positive_samples = dict()\n",
        "  negative_samples = dict()\n",
        "  target_words = set()\n",
        "\n",
        "  if isdataframe:\n",
        "    data=data['Sentence_preprocessed']\n",
        "\n",
        "  vocab, _, _ , _ = form_vocab(data, isdataframe=False)\n",
        "  # q=1\n",
        "  for sentence in data:\n",
        "    words = sentence.split()\n",
        "    num_words = len(words)\n",
        "    # print(f\"on sentece {q}\")\n",
        "    # q+=1\n",
        "    for i in range(0,num_words):\n",
        "        target_words.add(words[i])\n",
        "        if words[i] not in positive_samples:\n",
        "          positive_samples[words[i]] = set()\n",
        "        if words[i] not in negative_samples:\n",
        "          negative_samples[words[i]] = set()\n",
        "\n",
        "        for j in range(1,window_size+1):\n",
        "          if ((i-j)>=0):\n",
        "            positive_samples[words[i]].add(words[i-j])\n",
        "          if((i+j)<num_words):\n",
        "            positive_samples[words[i]].add(words[i+j])\n",
        "        # print(f\"Data type of vocab is {type(vocab)}, words[[i]] is {type(words[i])}, positive_words is {type(positive_samples[words[i]])}\")\n",
        "        negative_words =  vocab - set(words[i]) - positive_samples[words[i]]\n",
        "        negative_samples[words[i]] = set(sample(list(negative_words), k))\n",
        "  positive_samples = {target: list(context) for target, context in positive_samples.items()}\n",
        "  negative_samples = {target: list(context) for target, context in negative_samples.items()}\n",
        "\n",
        "  return positive_samples, negative_samples, list(target_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Db5ME1_7F3Gy"
      },
      "outputs": [],
      "source": [
        "def convert_to_index(positive_samples, negative_samples,target_words, word2index):\n",
        "\n",
        "  target_words_index = list()\n",
        "  positive_samples_index = dict()\n",
        "  negative_samples_index = dict()\n",
        "\n",
        "  for k in (target_words):\n",
        "    w_idx = word2index[k]\n",
        "    target_words_index.append(w_idx)\n",
        "\n",
        "    positive_samples_index[w_idx] = [word2index[i] for i in positive_samples[k]]\n",
        "    negative_samples_index[w_idx] = [word2index[i] for i in negative_samples[k]]\n",
        "\n",
        "  return target_words_index, positive_samples_index, negative_samples_index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_target_and_context_index(data, window_size,word2index, index2word, k=5, isdataframe=True):\n",
        "  print(\"The data is of shape:\\t\", data.shape)\n",
        "  positive_samples, negative_samples, target_words = skip_gram(data, window_size,k=5, isdataframe=True)\n",
        "  print(\"Created the target words and positive and negative context words pair.\\n\")\n",
        "  w = choice(target_words)\n",
        "  idx = word2index[w]\n",
        "  print(\"Printing an example...\")\n",
        "  print(f\"For word at index {idx}:\\t {w}\")\n",
        "  print(\"It's positive samples are:\\t\",positive_samples[w])\n",
        "  print(\"It's negative samples are:\\t\",negative_samples[w])\n",
        "  target_words_index, positive_samples_index, negative_samples_index = convert_to_index(positive_samples, negative_samples, target_words, word2index)\n",
        "  print(f\"\\nCreated the target words and context words pair using the index for training.\\n \")\n",
        "  print(index2word[idx], \"index:\\t\", idx)\n",
        "  print(\"Postive samples are:\\t\",positive_samples_index[idx])\n",
        "  print(\"Negative samples are:\\t\",negative_samples_index[idx])\n",
        "\n",
        "  return target_words_index, positive_samples_index, negative_samples_index"
      ],
      "metadata": {
        "id": "1d-MOVLBzVPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6yeilfGQaH7"
      },
      "outputs": [],
      "source": [
        "def form_data(target_words_index, positive_samples_index, negative_samples_index, index2word):\n",
        "  X_train = []\n",
        "  y_train = []\n",
        "\n",
        "  for target in target_words_index:\n",
        "\n",
        "    if target not in positive_samples_index or len(positive_samples_index[target]) == 0:\n",
        "      print(f\"No positive samples for target index {target}: {index2word[target]}\")\n",
        "      continue\n",
        "\n",
        "    if target not in negative_samples_index or len(negative_samples_index[target]) == 0:\n",
        "      print(f\"No negative samples for target index {target}: {index2word[target]}\")\n",
        "      continue\n",
        "    target_positive_pairs = np.array([[target,pos] for pos in positive_samples_index[target]],dtype=np.int32)\n",
        "    X_train.append(target_positive_pairs)\n",
        "    y_train.append(np.ones(len(target_positive_pairs),dtype=np.int32))\n",
        "\n",
        "    target_negative_pairs = [[target,neg] for neg in negative_samples_index[target]]\n",
        "    X_train.append(target_negative_pairs)\n",
        "    y_train.append(np.zeros(len(target_negative_pairs),dtype=np.int32))\n",
        "\n",
        "  return np.vstack(X_train), np.concatenate(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-wcV8giSYTr"
      },
      "outputs": [],
      "source": [
        "def create_training_data(target_words_index, positive_samples_index, negative_samples_index, index2word):\n",
        "  X_train,y_train = form_data(target_words_index, positive_samples_index, negative_samples_index, index2word)\n",
        "  print(f\"The total number of target words are:\\t{len(target_words_index)}.\\nThe total number of positive samples are:\\t{len(positive_samples_index)}.\\nThe total number of negative samples are:\\t{len(negative_samples_index)}\")\n",
        "  print(\"\\nCreated data for training.\")\n",
        "  print(\"Shape of training data is\", X_train.shape)\n",
        "  print(\"Printing the head of the training data..\\n\")\n",
        "  print(pd.DataFrame(X_train).head)\n",
        "  return X_train, y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMChAxQFNbS1"
      },
      "outputs": [],
      "source": [
        "def create_word2vec(X_train, y_train, vocab_size, name, index2word, word2index, epochs=10, batch_size=32):\n",
        "\n",
        "    target_words = X_train[:, 0]\n",
        "    context_words = X_train[:, 1]\n",
        "\n",
        "    # Input: (target words,context words)\n",
        "    target_ip = tf.keras.Input(shape=(),dtype=np.int32,name='target')\n",
        "    context_ip = tf.keras.Input(shape=(),dtype=np.int32,name='context')\n",
        "\n",
        "    target_emb_layers = tf.keras.layers.Embedding(vocab_size, 100, name='target_embed')  # Initializes a random embedding for target words.\n",
        "    context_emb_layers = tf.keras.layers.Embedding(vocab_size, 100, name='context_embed')  # Initializes a random embedding for context words.\n",
        "\n",
        "    target_emb = target_emb_layers(target_ip)\n",
        "    context_emb = context_emb_layers(context_ip)\n",
        "\n",
        "    # Dot product between tsrget and context embedding for finding the similiarity\n",
        "    dot_product = tf.keras.layers.Lambda(lambda x: tf.reduce_sum(x[0] * x[1], axis=1))([target_emb, context_emb])\n",
        "    output = tf.keras.layers.Activation(\"sigmoid\")(dot_product)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[target_ip, context_ip], outputs = output)\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "    loss_function = tf.keras.losses.BinaryCrossentropy(from_logits=False) # binary classification\n",
        "    model.compile(optimizer=optimizer, loss=loss_function, metrics=['accuracy'])\n",
        "\n",
        "    tf.keras.utils.set_random_seed(42)\n",
        "    model.fit([target_words, context_words], y_train, epochs=epochs, batch_size=batch_size)\n",
        "    print(\"Model training complete\")\n",
        "\n",
        "    target_embeddings = model.get_layer(\"target_embed\").get_weights()[0]\n",
        "    print(\"The shape of the embedding for target words created is:\", target_embeddings.shape)\n",
        "\n",
        "    context_embeddings = model.get_layer(\"context_embed\").get_weights()[0]\n",
        "    print(\"The shape of the embedding for context words created is:\", context_embeddings.shape)\n",
        "\n",
        "    final_embeddings = (target_embeddings + context_embeddings) / 2\n",
        "    print(\"Shape of final merged embeddings:\", final_embeddings.shape)\n",
        "\n",
        "    np.save(f\"{name}_embeddings.npy\", final_embeddings)\n",
        "\n",
        "    return model, final_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5t_D35fRzgv"
      },
      "outputs": [],
      "source": [
        "def load_embeddings(name):\n",
        "   file_path = f\"/content/DSE318-NLP-Assignment-Solutions/Assignment2/embeddings/{name}_embeddings.npy\"\n",
        "   return np.load(file_path, allow_pickle=True).astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOfiHE7madtF"
      },
      "source": [
        "## TRAIN FFNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data_for_FFNN(train, val,word2index):\n",
        "\n",
        "  X_train = train['Sentence_preprocessed']\n",
        "  y_train = train['Tag']\n",
        "  X_val = val['Sentence_preprocessed']\n",
        "  y_val = val['Tag']\n",
        "  X_train = [[word2index[word] for word in sentence.split() if word in word2index] for sentence in X_train]\n",
        "  X_val = [[word2index[word] for word in sentence.split() if word in word2index] for sentence in X_val]\n",
        "  padlen = max(max(map(len, X_train)), max(map(len, X_val)))\n",
        "  X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=padlen, padding='post')\n",
        "  X_val = tf.keras.preprocessing.sequence.pad_sequences(X_val, maxlen=padlen, padding='post')\n",
        "\n",
        "  return X_train, np.array(y_train), X_val, np.array(y_val)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jQmxwtA3hN5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qP0735QaSDEV"
      },
      "outputs": [],
      "source": [
        "def ffnn(name,vocab_size,X_train, y_train, epochs = 10, batch_size = 32):\n",
        "\n",
        "  print(\"Loading the embeddings..\\n\")\n",
        "  embeddings = load_embeddings(name)\n",
        "  embedding_dim = embeddings.shape[1]\n",
        "\n",
        "  print(\"Training the model...\\n\")\n",
        "  model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(input_dim = vocab_size, output_dim = embedding_dim, mask_zero=True,weights=[embeddings], trainable=True),\n",
        "        tf.keras.layers.GlobalAveragePooling1D(),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "  model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  class_weights = compute_class_weight(\"balanced\", classes=np.unique(y_train), y=y_train)\n",
        "  class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
        "\n",
        "\n",
        "  model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, class_weight=class_weight_dict)\n",
        "\n",
        "  print(\"Model training complete!\")\n",
        "\n",
        "  model_filename = f\"{name}_model.keras\"\n",
        "  model.save(model_filename)\n",
        "  print(f\"Model saved as {model_filename}\")\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCB64wDFHQGv"
      },
      "source": [
        "## EVALUATE FFNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lizlSnc0Yvqb"
      },
      "outputs": [],
      "source": [
        "def load_model(name):\n",
        "   model = tf.keras.models.load_model(f\"/content/DSE318-NLP-Assignment-Solutions/Assignment2/models/{name}_model.keras\")\n",
        "   print(f\"Model {model} loaded successfully!\")\n",
        "   return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ_GiZk0YvlU"
      },
      "outputs": [],
      "source": [
        "def evaluate(name, word2index, X, y):\n",
        "  target_names = [name, f\"non_{name}\"]\n",
        "  model = load_model(name)\n",
        "  y_pred_proba = model.predict(X)\n",
        "  y_pred = (y_pred_proba > 0.4).astype(int)\n",
        "  print(classification_report(y, y_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YxXnPkJPYvi-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZLiDT1QYvd_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6vZExYrYwGM"
      },
      "source": [
        "## HATE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4mLtFhpYxsi"
      },
      "outputs": [],
      "source": [
        "hate_train, hate_val = load_and_preprocess_data('hate')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqNK3WGQY0ax",
        "outputId": "84145476-93c3-4a08-b21c-33dceba2f88c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary of 12934 created\n"
          ]
        }
      ],
      "source": [
        "hate_vocab, hate_vocab_size, hate_word2index, hate_index2word = form_vocab(hate_train,isdataframe=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hate_target_words_index, hate_positive_samples_index, hate_negative_samples_index = create_target_and_context_index(data= hate_train, word2index=hate_word2index, index2word=hate_index2word,window_size = 4 , k=10, isdataframe = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUZ3ZXLzzthk",
        "outputId": "c458a669-c3a1-4c7b-dd6d-d9001b7653db",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The data is of shape:\t (3660, 3)\n",
            "Vocabulary of 12934 created\n",
            "Created the target words and positive and negative context words pair.\n",
            "\n",
            "Printing an example...\n",
            "For word at index 2839:\t maarliek\n",
            "It's positive samples are:\t ['ne', 'k', 'ki', 'mohenjodaro', 'sath', 'bhi', 'hritik', 'hadonone']\n",
            "It's negative samples are:\t ['agar', 'lost', 'ajeebogareeb', 'ba', 'bana']\n",
            "\n",
            "Created the target words and context words pair using the index for training.\n",
            " \n",
            "maarliek index:\t 2839\n",
            "Postive samples are:\t [99, 307, 41, 2840, 302, 201, 2838, 2837]\n",
            "Negative samples are:\t [486, 10076, 10361, 1927, 572]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k-M7219ZAMH",
        "outputId": "1620f7b5-7b8a-4bc8-c4e4-ec0a9a4d24de",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No positive samples for target index 6804: khudaneapnebandokoamankapaigamlekarbhejahaiyarapekalisensdekar\n",
            "The total number of target words are:\t12934.\n",
            "The total number of positive samples are:\t12934.\n",
            "The total number of negative samples are:\t12934\n",
            "\n",
            "Created data for training.\n",
            "Shape of training data is (379572, 2)\n",
            "Printing the head of the training data..\n",
            "\n",
            "<bound method NDFrame.head of             0      1\n",
            "0        1248   1250\n",
            "1        1248   1247\n",
            "2        1248   1249\n",
            "3        1248     23\n",
            "4        1248   1245\n",
            "...       ...    ...\n",
            "379567  10582   7327\n",
            "379568  10582   6453\n",
            "379569  10582   3002\n",
            "379570  10582  12222\n",
            "379571  10582   1213\n",
            "\n",
            "[379572 rows x 2 columns]>\n"
          ]
        }
      ],
      "source": [
        "X_hate_train, y_hate_train = create_training_data(hate_target_words_index, hate_positive_samples_index, hate_negative_samples_index, hate_index2word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhnLkjDjZP2h",
        "outputId": "7f972d61-c0e9-4082-aa27-05d908698681",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.0085 - loss: 0.5909\n",
            "Epoch 2/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.0319 - loss: 0.2712\n",
            "Epoch 3/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.1013 - loss: 0.2277\n",
            "Epoch 4/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.1342 - loss: 0.1719\n",
            "Epoch 5/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.1546 - loss: 0.1104\n",
            "Epoch 6/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.1654 - loss: 0.0606\n",
            "Epoch 7/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.1869 - loss: 0.0294\n",
            "Epoch 8/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.2165 - loss: 0.0131\n",
            "Epoch 9/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.2481 - loss: 0.0054\n",
            "Epoch 10/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.2911 - loss: 0.0022\n",
            "Epoch 11/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.3304 - loss: 8.3172e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.3680 - loss: 3.1516e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.4006 - loss: 1.2282e-04\n",
            "Epoch 14/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - accuracy: 0.4218 - loss: 5.3088e-05\n",
            "Epoch 15/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.4524 - loss: 2.7065e-05\n",
            "Epoch 16/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.4695 - loss: 1.6303e-05\n",
            "Epoch 17/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.4781 - loss: 1.1291e-05\n",
            "Epoch 18/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.4885 - loss: 8.5946e-06\n",
            "Epoch 19/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.4991 - loss: 6.9472e-06\n",
            "Epoch 20/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.5072 - loss: 5.8361e-06\n",
            "Epoch 21/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.5148 - loss: 5.0328e-06\n",
            "Epoch 22/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.5199 - loss: 4.4229e-06\n",
            "Epoch 23/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.5227 - loss: 3.9432e-06\n",
            "Epoch 24/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.5255 - loss: 3.5558e-06\n",
            "Epoch 25/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.5315 - loss: 3.2362e-06\n",
            "Epoch 26/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.5354 - loss: 2.9680e-06\n",
            "Epoch 27/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.5383 - loss: 2.7399e-06\n",
            "Epoch 28/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.5427 - loss: 2.5435e-06\n",
            "Epoch 29/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.5465 - loss: 2.3726e-06\n",
            "Epoch 30/30\n",
            "\u001b[1m2966/2966\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.5501 - loss: 2.2226e-06\n",
            "Model training complete\n",
            "The shape of the embedding for target words created is: (12934, 100)\n",
            "The shape of the embedding for context words created is: (12934, 100)\n",
            "Shape of final merged embeddings: (12934, 100)\n"
          ]
        }
      ],
      "source": [
        "# # time - 4m\n",
        "# hate_word2vec_model, hate_embeddings = create_word2vec(X_hate_train, y_hate_train, hate_vocab_size, 'hate', hate_index2word, hate_word2index, epochs=30, batch_size=128)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_hate, y_train_hate, X_val_hate, y_val_hate = prepare_data_for_FFNN(hate_train, hate_val, hate_word2index)\n"
      ],
      "metadata": {
        "id": "0EkecFGGiOKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x61JLagKguo7",
        "outputId": "c2f7cbfe-752f-4ec4-b81a-22801bff1bc2",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the embeddings..\n",
            "\n",
            "Training the model...\n",
            "\n",
            "Epoch 1/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5576 - loss: 0.6850\n",
            "Epoch 2/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6274 - loss: 0.6493\n",
            "Epoch 3/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6901 - loss: 0.6121\n",
            "Epoch 4/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7393 - loss: 0.5563\n",
            "Epoch 5/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8030 - loss: 0.4785\n",
            "Epoch 6/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8564 - loss: 0.3899\n",
            "Epoch 7/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9042 - loss: 0.3022\n",
            "Epoch 8/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9375 - loss: 0.2251\n",
            "Epoch 9/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9635 - loss: 0.1626\n",
            "Epoch 10/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9784 - loss: 0.1171\n",
            "Epoch 11/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9871 - loss: 0.0860\n",
            "Epoch 12/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9902 - loss: 0.0690\n",
            "Epoch 13/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9884 - loss: 0.0604\n",
            "Epoch 14/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 0.0496\n",
            "Epoch 15/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0410\n",
            "Epoch 16/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0324\n",
            "Epoch 17/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0230\n",
            "Epoch 18/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0163\n",
            "Epoch 19/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9980 - loss: 0.0122\n",
            "Epoch 20/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9993 - loss: 0.0090\n",
            "Epoch 21/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0071\n",
            "Epoch 22/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0064\n",
            "Epoch 23/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0063\n",
            "Epoch 24/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0054\n",
            "Epoch 25/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9990 - loss: 0.0045\n",
            "Epoch 26/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0036\n",
            "Epoch 27/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0029\n",
            "Epoch 28/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0024\n",
            "Epoch 29/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0020\n",
            "Epoch 30/30\n",
            "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0017\n",
            "Model training complete!\n",
            "Model saved as hate_model.keras\n"
          ]
        }
      ],
      "source": [
        "# hate_ffnn_model = ffnn('hate', hate_vocab_size, X_train_hate, y_train_hate,epochs=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH88qXOg6YN8",
        "outputId": "a1332bde-29d2-4ada-8c10-3054549abc53",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model <Sequential name=sequential, built=True> loaded successfully!\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.75      0.70      0.72       309\n",
            "    non_hate       0.45      0.53      0.49       148\n",
            "\n",
            "    accuracy                           0.64       457\n",
            "   macro avg       0.60      0.61      0.61       457\n",
            "weighted avg       0.66      0.64      0.65       457\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate('hate', hate_word2index,X_val_hate, y_val_hate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4T7QurbCW2Y"
      },
      "source": [
        "## SARCASM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyR_fVC1CVSr"
      },
      "outputs": [],
      "source": [
        "sarcasm_train, sarcasm_val = load_and_preprocess_data('sarcasm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqgNO3-DCcVS",
        "outputId": "41b0053b-de09-424a-97b7-4e0309ff3146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary of 14559 created\n"
          ]
        }
      ],
      "source": [
        "sarcasm_vocab, sarcasm_vocab_size, sarcasm_word2index, sarcasm_index2word = form_vocab(sarcasm_train,isdataframe=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sarcasm_target_words_index, sarcasm_positive_samples_index, sarcasm_negative_samples_index = create_target_and_context_index(data= sarcasm_train, word2index=sarcasm_word2index, index2word=sarcasm_index2word,window_size = 4 , k=10, isdataframe = True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xvy2DvyTYUvO",
        "outputId": "2f5ced89-97b6-45c8-eb49-195cfd27168e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The data is of shape:\t (4200, 3)\n",
            "Vocabulary of 14559 created\n",
            "Created the target words and positive and negative context words pair.\n",
            "\n",
            "Printing an example...\n",
            "For word at index 6766:\t werna\n",
            "It's positive samples are:\t ['chahiyay', 'honi', 'ko', 'pehun', 'lainn', 'choordiyann', 'un']\n",
            "It's negative samples are:\t ['tajziyae', 'khelane', 'respect', 'tarekfatah', 'balley']\n",
            "\n",
            "Created the target words and context words pair using the index for training.\n",
            " \n",
            "werna index:\t 6766\n",
            "Postive samples are:\t [6765, 1340, 55, 6768, 6769, 6767, 2524]\n",
            "Negative samples are:\t [11822, 7900, 1890, 11354, 10678]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fixiqnw0ClLj",
        "outputId": "19ef220f-c3af-45e9-af7d-4ddd95444519"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No positive samples for target index 9746: mosadnebdlaliyalakhlakhshukrahaiisrailecricketnahikheltevarnasirfseriesraddhotiaurmamlathandapadjata\n",
            "The total number of target words are:\t14559.\n",
            "The total number of positive samples are:\t14559.\n",
            "The total number of negative samples are:\t14559\n",
            "\n",
            "Created data for training.\n",
            "Shape of training data is (411764, 2)\n",
            "Printing the head of the training data..\n",
            "\n",
            "<bound method NDFrame.head of            0      1\n",
            "0       9393    196\n",
            "1       9393   1919\n",
            "2       9393   1300\n",
            "3       9393     56\n",
            "4       9393    197\n",
            "...      ...    ...\n",
            "411759  6142   8928\n",
            "411760  6142  11446\n",
            "411761  6142   7078\n",
            "411762  6142    645\n",
            "411763  6142  11852\n",
            "\n",
            "[411764 rows x 2 columns]>\n"
          ]
        }
      ],
      "source": [
        "# X_sarcasm_train, y_sarcasm_train = create_training_data(sarcasm_target_words_index, sarcasm_positive_samples_index, sarcasm_negative_samples_index, sarcasm_index2word)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Svq-tBQ6Cp2C",
        "outputId": "a191c798-e150-4475-e356-3a5b4519cd52",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.0079 - loss: 0.5912\n",
            "Epoch 2/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - accuracy: 0.0233 - loss: 0.2800\n",
            "Epoch 3/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.0825 - loss: 0.2343\n",
            "Epoch 4/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 4ms/step - accuracy: 0.1199 - loss: 0.1741\n",
            "Epoch 5/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.1431 - loss: 0.1089\n",
            "Epoch 6/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.1549 - loss: 0.0576\n",
            "Epoch 7/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.1778 - loss: 0.0268\n",
            "Epoch 8/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.2069 - loss: 0.0113\n",
            "Epoch 9/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 4ms/step - accuracy: 0.2465 - loss: 0.0045\n",
            "Epoch 10/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.2936 - loss: 0.0017\n",
            "Epoch 11/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.3464 - loss: 6.1025e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.3875 - loss: 2.2232e-04\n",
            "Epoch 13/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.4221 - loss: 8.6525e-05\n",
            "Epoch 14/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.4475 - loss: 3.9005e-05\n",
            "Epoch 15/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.4707 - loss: 2.1126e-05\n",
            "Epoch 16/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4ms/step - accuracy: 0.4865 - loss: 1.3623e-05\n",
            "Epoch 17/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.4947 - loss: 9.9418e-06\n",
            "Epoch 18/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.5010 - loss: 7.8382e-06\n",
            "Epoch 19/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.5077 - loss: 6.4806e-06\n",
            "Epoch 20/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 4ms/step - accuracy: 0.5162 - loss: 5.5272e-06\n",
            "Epoch 21/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 3ms/step - accuracy: 0.5216 - loss: 4.8179e-06\n",
            "Epoch 22/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.5267 - loss: 4.2683e-06\n",
            "Epoch 23/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 3ms/step - accuracy: 0.5313 - loss: 3.8294e-06\n",
            "Epoch 24/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4ms/step - accuracy: 0.5343 - loss: 3.4708e-06\n",
            "Epoch 25/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.5383 - loss: 3.1722e-06\n",
            "Epoch 26/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 3ms/step - accuracy: 0.5422 - loss: 2.9197e-06\n",
            "Epoch 27/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2ms/step - accuracy: 0.5467 - loss: 2.7035e-06\n",
            "Epoch 28/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3ms/step - accuracy: 0.5502 - loss: 2.5164e-06\n",
            "Epoch 29/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.5518 - loss: 2.3527e-06\n",
            "Epoch 30/30\n",
            "\u001b[1m3217/3217\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.5549 - loss: 2.2085e-06\n",
            "Model training complete\n",
            "The shape of the embedding for target words created is: (14559, 100)\n",
            "The shape of the embedding for context words created is: (14559, 100)\n",
            "Shape of final merged embeddings: (14559, 100)\n"
          ]
        }
      ],
      "source": [
        "# sarcasm_word2vec_model, sarcasm_embeddings = create_word2vec(X_sarcasm_train, y_sarcasm_train, sarcasm_vocab_size, 'sarcasm', sarcasm_index2word, sarcasm_word2index, epochs=30, batch_size=128)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBDDRwhgEuiJ"
      },
      "outputs": [],
      "source": [
        "X_train_sarcasm, y_train_sarcasm, X_val_sarcasm, y_val_sarcasm = prepare_data_for_FFNN(sarcasm_train, sarcasm_val, sarcasm_word2index)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sarcasm_ffnn_model = ffnn('sarcasm', sarcasm_vocab_size, X_train_sarcasm, y_train_sarcasm,epochs=30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vsN22uAZnDT7",
        "outputId": "ad6ab61a-14db-4115-8cc1-039ace565589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the embeddings..\n",
            "\n",
            "Training the model...\n",
            "\n",
            "Epoch 1/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.7676 - loss: 0.6508\n",
            "Epoch 2/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9112 - loss: 0.3561\n",
            "Epoch 3/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9456 - loss: 0.1864\n",
            "Epoch 4/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9533 - loss: 0.1237\n",
            "Epoch 5/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9639 - loss: 0.0893\n",
            "Epoch 6/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9695 - loss: 0.0667\n",
            "Epoch 7/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9767 - loss: 0.0486\n",
            "Epoch 8/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9852 - loss: 0.0336\n",
            "Epoch 9/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9912 - loss: 0.0223\n",
            "Epoch 10/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9940 - loss: 0.0145\n",
            "Epoch 11/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9966 - loss: 0.0094\n",
            "Epoch 12/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0062\n",
            "Epoch 13/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0043\n",
            "Epoch 14/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0031\n",
            "Epoch 15/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0023\n",
            "Epoch 16/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0018\n",
            "Epoch 17/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0014\n",
            "Epoch 18/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0011\n",
            "Epoch 19/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 9.2777e-04\n",
            "Epoch 20/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.7379e-04\n",
            "Epoch 21/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 6.5266e-04\n",
            "Epoch 22/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.5549e-04\n",
            "Epoch 23/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.7677e-04\n",
            "Epoch 24/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.1202e-04\n",
            "Epoch 25/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.5833e-04\n",
            "Epoch 26/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1334e-04\n",
            "Epoch 27/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.7533e-04\n",
            "Epoch 28/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.4295e-04\n",
            "Epoch 29/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.1518e-04\n",
            "Epoch 30/30\n",
            "\u001b[1m132/132\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9123e-04\n",
            "Model training complete!\n",
            "Model saved as sarcasm_model.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate('sarcasm', sarcasm_word2index,X_val_sarcasm, y_val_sarcasm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecYd2u6cnM7F",
        "outputId": "fb3cf834-712c-4eb3-f8ba-efc306db49ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model <Sequential name=sequential_1, built=True> loaded successfully!\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     sarcasm       0.97      0.98      0.98       474\n",
            " non_sarcasm       0.79      0.75      0.77        51\n",
            "\n",
            "    accuracy                           0.96       525\n",
            "   macro avg       0.88      0.86      0.87       525\n",
            "weighted avg       0.96      0.96      0.96       525\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al9mp3uHFZrZ"
      },
      "source": [
        "## Humor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hxQEFMfDvv4"
      },
      "outputs": [],
      "source": [
        "humor_train, humor_val = load_and_preprocess_data('humor')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mmvk2Q-Hl0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b3f26d-f5ea-4448-e414-76062b2ddfe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary of 7179 created\n"
          ]
        }
      ],
      "source": [
        "humor_vocab, humor_vocab_size, humor_word2index, humor_index2word = form_vocab(humor_train,isdataframe=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# humor_target_words_index, humor_positive_samples_index, humor_negative_samples_index = create_target_and_context_index(data= humor_train, word2index=humor_word2index, index2word=humor_index2word,window_size = 4 , k=10, isdataframe = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gpi-YhhLncrq",
        "outputId": "8d446e81-f687-4966-9dc3-05fdb3e11640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The data is of shape:\t (2360, 3)\n",
            "Vocabulary of 7179 created\n",
            "Created the target words and positive and negative context words pair.\n",
            "\n",
            "Printing an example...\n",
            "For word at index 5317:\t place\n",
            "It's positive samples are:\t ['to', 'special', 'in', 'hell', 'best', 'for', 'salman', 'people', 'bhai']\n",
            "It's negative samples are:\t ['melted', 'ji', 'dekha', 'phorengay', 'bahu']\n",
            "\n",
            "Created the target words and context words pair using the index for training.\n",
            " \n",
            "place index:\t 5317\n",
            "Postive samples are:\t [30, 3354, 315, 6961, 974, 118, 249, 314, 54]\n",
            "Negative samples are:\t [4468, 297, 1100, 5710, 149]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# X_humor_train, y_humor_train = create_training_data(humor_target_words_index, humor_positive_samples_index, humor_negative_samples_index, humor_index2word)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYOH1KNdnsx1",
        "outputId": "d1a43f8d-76e5-4cab-80dd-223993e21024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The total number of target words are:\t7179.\n",
            "The total number of positive samples are:\t7179.\n",
            "The total number of negative samples are:\t7179\n",
            "\n",
            "Created data for training.\n",
            "Shape of training data is (178858, 2)\n",
            "Printing the head of the training data..\n",
            "\n",
            "<bound method NDFrame.head of            0     1\n",
            "0       3179  3180\n",
            "1       3179    23\n",
            "2       3179    69\n",
            "3       3179  3181\n",
            "4       3179    63\n",
            "...      ...   ...\n",
            "178853  6736  1540\n",
            "178854  6736  4342\n",
            "178855  6736  5337\n",
            "178856  6736  6242\n",
            "178857  6736  5248\n",
            "\n",
            "[178858 rows x 2 columns]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# humor_word2vec_model, humor_embeddings = create_word2vec(X_humor_train, y_humor_train, humor_vocab_size, 'humor', humor_index2word, humor_word2index, epochs=30, batch_size=128)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU-8PsJDn46g",
        "outputId": "7483b89d-a325-4c36-e2b3-1b4c0de0f806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0031 - loss: 0.6601\n",
            "Epoch 2/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0059 - loss: 0.3497\n",
            "Epoch 3/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.0165 - loss: 0.2903\n",
            "Epoch 4/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0351 - loss: 0.2410\n",
            "Epoch 5/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0618 - loss: 0.1822\n",
            "Epoch 6/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0782 - loss: 0.1240\n",
            "Epoch 7/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.0885 - loss: 0.0768\n",
            "Epoch 8/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1061 - loss: 0.0443\n",
            "Epoch 9/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1163 - loss: 0.0244\n",
            "Epoch 10/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1248 - loss: 0.0131\n",
            "Epoch 11/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1493 - loss: 0.0069\n",
            "Epoch 12/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1682 - loss: 0.0036\n",
            "Epoch 13/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1799 - loss: 0.0019\n",
            "Epoch 14/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.2007 - loss: 9.6690e-04\n",
            "Epoch 15/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2272 - loss: 5.0744e-04\n",
            "Epoch 16/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2491 - loss: 2.7054e-04\n",
            "Epoch 17/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.2675 - loss: 1.4812e-04\n",
            "Epoch 18/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.2941 - loss: 8.4387e-05\n",
            "Epoch 19/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.3149 - loss: 5.0699e-05\n",
            "Epoch 20/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3304 - loss: 3.2437e-05\n",
            "Epoch 21/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.3429 - loss: 2.2170e-05\n",
            "Epoch 22/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3539 - loss: 1.6127e-05\n",
            "Epoch 23/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3631 - loss: 1.2377e-05\n",
            "Epoch 24/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3770 - loss: 9.9201e-06\n",
            "Epoch 25/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.3813 - loss: 8.2254e-06\n",
            "Epoch 26/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.3993 - loss: 7.0011e-06\n",
            "Epoch 27/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.3998 - loss: 6.0814e-06\n",
            "Epoch 28/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.4037 - loss: 5.3676e-06\n",
            "Epoch 29/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4076 - loss: 4.7986e-06\n",
            "Epoch 30/30\n",
            "\u001b[1m1398/1398\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4095 - loss: 4.3350e-06\n",
            "Model training complete\n",
            "The shape of the embedding for target words created is: (7179, 100)\n",
            "The shape of the embedding for context words created is: (7179, 100)\n",
            "Shape of final merged embeddings: (7179, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_humor, y_train_humor, X_val_humor, y_val_humor = prepare_data_for_FFNN(humor_train, humor_val, humor_word2index)\n"
      ],
      "metadata": {
        "id": "xYta_h8ooFF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# humor_ffnn_model = ffnn('humor', humor_vocab_size, X_train_humor, y_train_humor,epochs=30)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TBHUpvGyoNj2",
        "outputId": "754f9603-1b6e-49ff-9a5c-6d71278f409f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading the embeddings..\n",
            "\n",
            "Training the model...\n",
            "\n",
            "Epoch 1/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5002 - loss: 0.7059\n",
            "Epoch 2/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5432 - loss: 0.6784\n",
            "Epoch 3/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6056 - loss: 0.6553\n",
            "Epoch 4/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6652 - loss: 0.6230\n",
            "Epoch 5/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7271 - loss: 0.5747\n",
            "Epoch 6/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7874 - loss: 0.5113\n",
            "Epoch 7/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8328 - loss: 0.4325\n",
            "Epoch 8/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8730 - loss: 0.3441\n",
            "Epoch 9/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2602\n",
            "Epoch 10/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9482 - loss: 0.1867\n",
            "Epoch 11/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9668 - loss: 0.1366\n",
            "Epoch 12/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9709 - loss: 0.1082\n",
            "Epoch 13/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9667 - loss: 0.0996\n",
            "Epoch 14/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9727 - loss: 0.0890\n",
            "Epoch 15/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9895 - loss: 0.0484\n",
            "Epoch 16/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0391\n",
            "Epoch 17/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9919 - loss: 0.0364\n",
            "Epoch 18/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0235\n",
            "Epoch 19/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0147\n",
            "Epoch 20/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0128\n",
            "Epoch 21/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0113\n",
            "Epoch 22/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0101\n",
            "Epoch 23/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0090\n",
            "Epoch 24/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0080\n",
            "Epoch 25/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0071\n",
            "Epoch 26/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0062\n",
            "Epoch 27/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0054\n",
            "Epoch 28/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0048\n",
            "Epoch 29/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0043\n",
            "Epoch 30/30\n",
            "\u001b[1m74/74\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0038\n",
            "Model training complete!\n",
            "Model saved as humor_model.keras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate('humor', humor_word2index,X_val_humor, y_val_humor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2HezM-xoUfw",
        "outputId": "979af6d7-a969-4b23-cb11-7e3f61a61d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model <Sequential name=sequential_2, built=True> loaded successfully!\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       humor       0.59      0.45      0.51       119\n",
            "   non_humor       0.68      0.78      0.73       176\n",
            "\n",
            "    accuracy                           0.65       295\n",
            "   macro avg       0.63      0.62      0.62       295\n",
            "weighted avg       0.64      0.65      0.64       295\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lNIK2-5OqLCa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}