{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "warning: in the working copy of 'Assignment2/22161_jiyasinha_nlpassignment2.ipynb', LF will be replaced by CRLF the next time Git touches it\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[main 19e135e] commit\n",
            " 1 file changed, 5 insertions(+), 4 deletions(-)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "To https://github.com/sinhajiya/DSE318-NLP-Assignment-Solutions.git\n",
            "   34b3400..19e135e  main -> main\n"
          ]
        }
      ],
      "source": [
        "!git add .\n",
        "!git commit -m \"commit\"\n",
        "!git push origin main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQG7XB_AmoIn"
      },
      "source": [
        "## IMPORTING LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FCHjQEZQmqOK"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from random import randint, choice, seed\n",
        "import tensorflow as tf\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from imblearn.under_sampling import RandomUnderSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URSlBvqvRNP0",
        "outputId": "34091378-28b8-497e-da57-29ffa0a56b70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fvNQ6odmlns"
      },
      "source": [
        "## LOADING DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jk9Zbtj3mERg",
        "outputId": "54ec468d-11d9-4eb6-a8d0-90b0fcbdce87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Assignment_1_2025'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 35 (delta 6), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (35/35), 1.06 MiB | 7.38 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/islnlp/Assignment_1_2025"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YusdjrNyYEe0",
        "outputId": "b6b6de99-e992-4e79-c07e-ae0de8b30e3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'DSE318-NLP-Assignment-Solutions'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 76 (delta 0), reused 5 (delta 0), pack-reused 70 (from 1)\u001b[K\n",
            "Receiving objects: 100% (76/76), 70.73 MiB | 12.80 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/sinhajiya/DSE318-NLP-Assignment-Solutions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FoCGMiUqmYQg"
      },
      "outputs": [],
      "source": [
        "def load_data(name):\n",
        "  root_fp = f\"/content/Assignment_1_2025/{name}\"\n",
        "  train = pd.read_csv(os.path.join(root_fp, \"train.csv\"))\n",
        "  val = pd.read_csv(os.path.join(root_fp, \"val.csv\"))\n",
        "  train = train.dropna(subset=['Sentence'])\n",
        "  val = val.dropna(subset=['Sentence'])\n",
        "  return train, val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LX4iA9aPmax3"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(Sentence):\n",
        "\n",
        "  # Preprocessing steps:\n",
        "  # 1. All lower case characters\n",
        "  # 2. URL removal\n",
        "  # 3. Multiple dots to single dot\n",
        "  # 4. Extra spaces to single space\n",
        "  # 5. Removes non-alphabetic chars\n",
        "\n",
        "    url_pattern = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*(),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
        "    Sentence = Sentence.lower()\n",
        "    Sentence = re.sub(url_pattern, \"\", Sentence)\n",
        "    Sentence = re.sub(r\"\\.{2,}\", \".\", Sentence)\n",
        "    Sentence = re.sub(r\"\\s+\", \" \", Sentence).strip()\n",
        "    Sentence = re.sub(r\"[^a-zA-Z\\s]\", \"\", Sentence)\n",
        "    return Sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bg15__OwmgH9"
      },
      "outputs": [],
      "source": [
        "def load_and_preprocess_data(name):\n",
        "\n",
        "  train, val = load_data(name)\n",
        "  train[\"Sentence_preprocessed\"] = train[\"Sentence\"].astype(str).apply(preprocess_text)\n",
        "  val[\"Sentence_preprocessed\"] = val[\"Sentence\"].astype(str).apply(preprocess_text)\n",
        "\n",
        "  return train, val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yCMTMEAzmyt-"
      },
      "outputs": [],
      "source": [
        "def form_vocab(data,isdataframe=True):\n",
        "\n",
        "  vocab_size = 0\n",
        "  vocab = set()\n",
        "  word2index = dict()  # Gives mapping from index to word\n",
        "  index2word = dict()  # Gives mapping of word to index\n",
        "\n",
        "  if isdataframe:\n",
        "    data = data[\"Sentence_preprocessed\"]\n",
        "\n",
        "  for sentence in data:\n",
        "    for word in sentence.split():\n",
        "      if word not in word2index:\n",
        "        word2index[word] = vocab_size\n",
        "        index2word[vocab_size] = word\n",
        "        vocab.add(word)\n",
        "        vocab_size += 1\n",
        "  print(f\"Vocabulary of {vocab_size} created\")\n",
        "  return vocab, vocab_size, word2index, index2word\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcXrCvxu23Wz"
      },
      "source": [
        "## WORD2VEC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "73fYUFZE05G0"
      },
      "outputs": [],
      "source": [
        "def skip_gram(data, window_size,k=5, isdataframe=True):\n",
        "  seed(42)\n",
        "\n",
        "  positive_samples = dict()\n",
        "  negative_samples = dict()\n",
        "  target_words = list()\n",
        "  if isdataframe:\n",
        "    data=data['Sentence_preprocessed']\n",
        "\n",
        "  vocab, _, _ , _ = form_vocab(data, isdataframe=False)\n",
        "\n",
        "  for sentence in data:\n",
        "    words = sentence.split()\n",
        "    num_words = len(words)\n",
        "\n",
        "    for i in range(0,num_words):\n",
        "        target_words.append(words[i])\n",
        "        positive_samples[words[i]] = list()\n",
        "        negative_samples[words[i]] = list()\n",
        "\n",
        "        for j in range(1,window_size+1):\n",
        "          if ((i-j)>=0):\n",
        "            positive_samples[words[i]].append(words[i-j])\n",
        "          if((i+j)<num_words):\n",
        "            positive_samples[words[i]].append(words[i+j])\n",
        "        l=0\n",
        "        while l<k:\n",
        "          negative_sample = choice(list(vocab))\n",
        "          if negative_sample != words[i] and negative_sample not in positive_samples[words[i]]:\n",
        "            negative_samples[words[i]].append(negative_sample)\n",
        "            l+=1\n",
        "\n",
        "    return positive_samples, negative_samples, target_words\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Db5ME1_7F3Gy"
      },
      "outputs": [],
      "source": [
        "def convert_to_index(positive_samples, negative_samples,target_words, word2index):\n",
        "\n",
        "  target_words_index = list()\n",
        "  positive_samples_index = dict()\n",
        "  negative_samples_index = dict()\n",
        "\n",
        "  for k in (target_words):\n",
        "    w_idx = word2index[k]\n",
        "    target_words_index.append(w_idx)\n",
        "\n",
        "    positive_samples_index[w_idx] = [word2index[i] for i in positive_samples[k]]\n",
        "    negative_samples_index[w_idx] = [word2index[i] for i in negative_samples[k]]\n",
        "\n",
        "\n",
        "  return target_words_index, positive_samples_index, negative_samples_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "n6yeilfGQaH7"
      },
      "outputs": [],
      "source": [
        "def form_data(target_words_index, positive_samples_index, negative_samples_index):\n",
        "\n",
        "  X_train = []\n",
        "  y_train = []\n",
        "\n",
        "  for target in target_words_index:\n",
        "      for pos in positive_samples_index[target]:\n",
        "          X_train.append([target])\n",
        "          y_train.append(1) #label =1\n",
        "\n",
        "      for neg in negative_samples_index[target]:\n",
        "          X_train.append([target])\n",
        "          y_train.append(0)  # label = 0\n",
        "\n",
        "  return np.array(X_train), np.array(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "i-wcV8giSYTr"
      },
      "outputs": [],
      "source": [
        "def create_data(data, window_size,word2index, index2word, k=5, isdataframe=True):\n",
        "\n",
        "  positive_samples, negative_samples, target_words = skip_gram(data, window_size,k=5, isdataframe=True)\n",
        "  print(\"Created the target words and context words pair\\n\")\n",
        "\n",
        "  w = index2word[window_size]\n",
        "  print(f\"For word at index {window_size}:\\t {w}\")\n",
        "  print(\"Positive samples are:\\t\",positive_samples[w])\n",
        "  print(\"Negative samples are:\\t\",negative_samples[w])\n",
        "\n",
        "  target_words_index, positive_samples_index, negative_samples_index = convert_to_index(positive_samples, negative_samples, target_words, word2index)\n",
        "  print(f\"\\nCreated the target words and context words pair using the index for training.\\n \")\n",
        "  print(index2word[window_size], \"index:\\t\", window_size)\n",
        "  print(\"Postive samples are:\\t\",positive_samples_index[window_size])\n",
        "  print(\"Negative samples are:\\t\",negative_samples_index[window_size])\n",
        "\n",
        "  X_train,y_train = form_data(target_words_index, positive_samples_index, negative_samples_index)\n",
        "  print(\"\\nCreated data for training.\")\n",
        "\n",
        "  return X_train, y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "aMChAxQFNbS1"
      },
      "outputs": [],
      "source": [
        "def create_word2vec(X_train, y_train, vocab_size, name, index2word, word2index, epochs=10, batch_size=32):\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, 100),  # Word Embeddings\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')  # Binary classification (positive/negative context)\n",
        "    ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    device = \"/GPU:0\" if tf.config.list_physical_devices('GPU') else \"/CPU:0\"\n",
        "    with tf.device(device):\n",
        "        model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "    print(\"Model training complete!\")\n",
        "\n",
        "    embeddings = model.layers[0].get_weights()[0]\n",
        "    print(\"The shape of the embedding created is: \",(np.asarray(embeddings)).shape)\n",
        "    word = index2word[y_train[0]]\n",
        "    input_vec = tf.convert_to_tensor([word2index[word]])\n",
        "    embedding_layer = model.layers[0]\n",
        "\n",
        "    print(\"Embedding for\", word, \":\", embedding_layer(input_vec).numpy().tolist())\n",
        "\n",
        "\n",
        "    np.save(f\"{name}_embeddings.npy\", embeddings)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "R5t_D35fRzgv"
      },
      "outputs": [],
      "source": [
        "def load_embeddings(name):\n",
        "   file_path = f\"/content/DSE318-NLP-Assignment-Solutions/Assignment2/embeddings/{name}_embeddings.npy\"\n",
        "   return np.load(file_path, allow_pickle=True).astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOfiHE7madtF"
      },
      "source": [
        "## TRAIN FFNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VKOC3cGvn_gr"
      },
      "outputs": [],
      "source": [
        "def prepare_data_for_FFNN(data, word2index,maxlen=30):\n",
        "\n",
        "  X_words = data['Sentence_preprocessed']\n",
        "  X= list()\n",
        "\n",
        "  for sentence in X_words:\n",
        "    s = [word2index.get(word, 0) for word in sentence.split()]\n",
        "    X.append(s)\n",
        "\n",
        "  X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=maxlen, padding='post')\n",
        "  X = np.array(X)\n",
        "  y = np.array(data['Tag'])\n",
        "  print(f\"Shape of the data is: X: {X.shape} and y: {y.shape}\")\n",
        "  print(\"\\nData is ready\")\n",
        "  return X,y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "qP0735QaSDEV"
      },
      "outputs": [],
      "source": [
        "def ffnn(name,vocab_size,X_train, y_train, epochs = 10, batch_size = 32,isclassbalanced=False):\n",
        "\n",
        "  if not isclassbalanced:\n",
        "    print(\"Resampling data due to class imbalance...\\n\")\n",
        "    print(f\"Class distribution before resampling: {Counter(y_train)}\")\n",
        "    undersampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
        "    X_train, y_train = undersampler.fit_resample(X_train, y_train)\n",
        "    print(f\"Class distribution after resampling: {Counter(y_train)}\")\n",
        "\n",
        "\n",
        "  print(\"Training the model...\\n\")\n",
        "  embeddings = load_embeddings(name)\n",
        "  model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, 100,weights=[embeddings], trainable=True),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "  model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  device = \"/GPU:0\" if tf.config.list_physical_devices('GPU') else \"/CPU:0\"\n",
        "  with tf.device(device):\n",
        "      model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "  print(\"Model training complete!\")\n",
        "\n",
        "  model_filename = f\"{name}_model.keras\"\n",
        "  model.save(model_filename)\n",
        "  print(f\"Model saved as {model_filename}\")\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCB64wDFHQGv"
      },
      "source": [
        "## EVALUATE FFNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "lizlSnc0Yvqb"
      },
      "outputs": [],
      "source": [
        "def load_model(name):\n",
        "   model = tf.keras.models.load_model(f\"/content/DSE318-NLP-Assignment-Solutions/Assignment2/models/{name}_model.keras\")\n",
        "   print(f\"Model {model} loaded successfully!\")\n",
        "   return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "gQ_GiZk0YvlU"
      },
      "outputs": [],
      "source": [
        "def evaluate(name, data, word2index):\n",
        "  target_names = [name, f\"non_{name}\"]\n",
        "  model = load_model(name)\n",
        "  X_test,y_true = prepare_data_for_FFNN(data, word2index)\n",
        "  y_pred_proba = model.predict(X_test)\n",
        "  y_pred = (y_pred_proba > 0.5).astype(int)\n",
        "  print(classification_report(y_true, y_pred, target_names=target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YxXnPkJPYvi-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "AZLiDT1QYvd_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6vZExYrYwGM"
      },
      "source": [
        "## HATE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-4mLtFhpYxsi"
      },
      "outputs": [],
      "source": [
        "hate_train, hate_val = load_and_preprocess_data('hate')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqNK3WGQY0ax",
        "outputId": "43fb5845-be98-4c4c-8cdb-751c0306fb82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary of 12934 created\n"
          ]
        }
      ],
      "source": [
        "hate_vocab, hate_vocab_size, hate_word2index, hate_index2word = form_vocab(hate_train,isdataframe=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k-M7219ZAMH",
        "outputId": "858b63db-9108-47a6-e0c6-306900e3a144"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary of 12934 created\n",
            "Created the target words and context words pair\n",
            "\n",
            "For word at index 4:\t teen\n",
            "Positive samples are:\t ['mey', 'bachchiyo', 'week', 'ke', 'ek', 'saath', 'mey', 'gang']\n",
            "Negative samples are:\t ['tarfa', 'rajpoot', 'jate', 'awais', 'level']\n",
            "\n",
            "Created the target words and context words pair using the index for training.\n",
            " \n",
            "teen index:\t 4\n",
            "Postive samples are:\t [1, 5, 3, 6, 2, 7, 1, 8]\n",
            "Negative samples are:\t [4320, 9733, 1099, 9063, 5247]\n",
            "\n",
            "Created data for training.\n"
          ]
        }
      ],
      "source": [
        "X_hate_train, y_hate_train = create_data(data= hate_train, word2index=hate_word2index, index2word=hate_index2word,window_size = 4 , k=5, isdataframe=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhnLkjDjZP2h",
        "outputId": "f46fd991-f0ee-45ef-c92e-bcf0d91b1f9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.4502 - loss: 0.6952\n",
            "Epoch 2/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5834 - loss: 0.6884 \n",
            "Epoch 3/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6037 - loss: 0.6860 \n",
            "Epoch 4/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6115 - loss: 0.6802 \n",
            "Epoch 5/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6226 - loss: 0.6758 \n",
            "Epoch 6/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6115 - loss: 0.6740 \n",
            "Epoch 7/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6086 - loss: 0.6762 \n",
            "Epoch 8/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5864 - loss: 0.6807 \n",
            "Epoch 9/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6048 - loss: 0.6732 \n",
            "Epoch 10/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6204 - loss: 0.6670 \n",
            "Epoch 11/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6358 - loss: 0.6619 \n",
            "Epoch 12/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5914 - loss: 0.6768 \n",
            "Epoch 13/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5931 - loss: 0.6723 \n",
            "Epoch 14/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5901 - loss: 0.6747 \n",
            "Epoch 15/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6023 - loss: 0.6671 \n",
            "Epoch 16/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6219 - loss: 0.6632 \n",
            "Epoch 17/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6446 - loss: 0.6573 \n",
            "Epoch 18/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6048 - loss: 0.6714 \n",
            "Epoch 19/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6199 - loss: 0.6654 \n",
            "Epoch 20/20\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6046 - loss: 0.6743 \n",
            "Model training complete!\n",
            "The shape of the embedding created is:  (12934, 100)\n",
            "Embedding for mey : [[-0.07308866083621979, -0.0658639520406723, -0.01411399245262146, 0.05578317120671272, 0.011806652881205082, 0.05311170965433121, 0.0017061028629541397, -0.05155917629599571, 0.01425923127681017, 0.062358319759368896, 0.024305205792188644, 0.041162386536598206, -0.017681561410427094, 0.015496990643441677, -0.02610786259174347, 0.06505315750837326, -0.057591456919908524, -0.06108953431248665, -0.0100467000156641, 0.04230542108416557, -0.018483484163880348, -0.04721268638968468, 0.0743212103843689, 0.043141741305589676, -0.049186959862709045, 0.023798566311597824, 0.0639384314417839, 0.00023780400806572288, 0.0022970952559262514, 0.014913409017026424, -0.0597061924636364, -0.06764785945415497, 0.003903206204995513, 0.0379667766392231, -0.004356810823082924, 0.00885854009538889, -0.020066898316144943, -0.018903251737356186, 0.06688522547483444, 0.044677410274744034, 0.021249594166874886, 0.06825584918260574, 0.03556402772665024, 0.042083363980054855, 0.03978900611400604, 0.007636601105332375, -0.016981974244117737, -0.020550332963466644, -0.07259198278188705, 0.008573560975492, 0.051786527037620544, -0.04246888309717178, -0.016865434125065804, -0.023752138018608093, -0.04910112917423248, 0.005498338956385851, 0.0667683407664299, 0.05851466581225395, 0.01025870256125927, 0.017915038391947746, 0.06569283455610275, -0.0555792972445488, -0.03837005794048309, 0.026140691712498665, -0.01812763512134552, 0.011185524053871632, 0.030468516051769257, -0.0298398956656456, -0.06946844607591629, -0.010525849647819996, -0.0176203902810812, -0.033222585916519165, -0.06392569839954376, 0.02610579878091812, -0.01667352393269539, 0.05855422839522362, 0.019778171554207802, 0.028695018962025642, 0.04224027693271637, 0.0025723734870553017, 0.009328958578407764, 0.02482939325273037, -0.008950420655310154, 0.022482292726635933, -0.006240180693566799, -0.058591898530721664, -0.04597200080752373, 0.05570284649729729, 0.06362137198448181, 0.05783630535006523, -0.008724275045096874, -0.012667455710470676, -0.049570005387067795, 0.058878716081380844, -0.03849821537733078, 0.06342925876379013, -0.015164334326982498, 0.05112403258681297, 0.013308265246450901, 0.06574086099863052]]\n"
          ]
        }
      ],
      "source": [
        "# hate_word2vec_model = create_word2vec(X_hate_train, y_hate_train, hate_vocab_size, 'hate', hate_index2word, hate_word2index, epochs=20, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6L4OAh5S7IPB",
        "outputId": "e32c796c-074b-4f45-c4ac-53acbbf40596"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of the data is: X: (3660, 30) and y: (3660,)\n",
            "\n",
            "Data is ready\n"
          ]
        }
      ],
      "source": [
        "hate_X_train, hate_y_train = prepare_data_for_FFNN(hate_train,hate_word2index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x61JLagKguo7",
        "outputId": "11f02217-e516-48bc-e825-11589fa694e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resampling data due to class imbalance...\n",
            "\n",
            "Class distribution before resampling: Counter({np.int64(0): 2307, np.int64(1): 1353})\n",
            "Class distribution after resampling: Counter({np.int64(0): 1353, np.int64(1): 1353})\n",
            "Training the model...\n",
            "\n",
            "Epoch 1/20\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5411 - loss: 0.6894\n",
            "Epoch 2/20\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8340 - loss: 0.4899\n",
            "Epoch 3/20\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9851 - loss: 0.0648\n",
            "Epoch 4/20\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0109\n",
            "Epoch 5/20\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0041\n",
            "Epoch 6/20\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0029\n",
            "Epoch 7/20\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0021\n",
            "Epoch 8/20\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0010\n",
            "Epoch 9/20\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.1307e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 5.9470e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 4.6871e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.6510e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.1929e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.5955e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4779e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.9195e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.8027e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.5228e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3197e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3542e-04\n",
            "Model training complete!\n",
            "Model saved as hate_model.keras\n"
          ]
        }
      ],
      "source": [
        "# hate_ffnn_model = ffnn('hate', hate_vocab_size, hate_X_train, hate_y_train,epochs=20, isclassbalanced=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH88qXOg6YN8",
        "outputId": "ae2d3450-8b96-4d16-c118-c794a998f175"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model <Sequential name=sequential_5, built=True> loaded successfully!\n",
            "Shape of the data is: X: (457, 30) and y: (457,)\n",
            "\n",
            "Data is ready\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        hate       0.73      0.63      0.68       309\n",
            "    non_hate       0.40      0.52      0.45       148\n",
            "\n",
            "    accuracy                           0.60       457\n",
            "   macro avg       0.57      0.58      0.57       457\n",
            "weighted avg       0.63      0.60      0.61       457\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate('hate',hate_val, hate_word2index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4T7QurbCW2Y"
      },
      "source": [
        "## SARCASM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "gyR_fVC1CVSr"
      },
      "outputs": [],
      "source": [
        "sarcasm_train, sarcasm_val = load_and_preprocess_data('sarcasm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqgNO3-DCcVS",
        "outputId": "00cc419a-e1ee-4b84-df75-a868078d72b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary of 14559 created\n"
          ]
        }
      ],
      "source": [
        "sarcasm_vocab, sarcasm_vocab_size, sarcasm_word2index, sarcasm_index2word = form_vocab(sarcasm_train,isdataframe=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fixiqnw0ClLj",
        "outputId": "fdf3089f-bf13-428b-f30c-163b7af84cac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary of 14559 created\n",
            "Created the target words and context words pair\n",
            "\n",
            "For word at index 4:\t black\n",
            "Positive samples are:\t ['meri', 'display', 'log', 'peh', 'jo', 'chorh', 'mashaallah', 'k']\n",
            "Negative samples are:\t ['rbhatkal', 'sports', 'noteban', 'cheenen', 'iliyana']\n",
            "\n",
            "Created the target words and context words pair using the index for training.\n",
            " \n",
            "black index:\t 4\n",
            "Postive samples are:\t [3, 5, 2, 6, 1, 7, 0, 8]\n",
            "Negative samples are:\t [396, 5502, 4542, 10432, 5812]\n",
            "\n",
            "Created data for training.\n"
          ]
        }
      ],
      "source": [
        "X_sarcasm_train, y_sarcasm_train = create_data(data= sarcasm_train, word2index=sarcasm_word2index, index2word=sarcasm_index2word,window_size = 4 , k=5, isdataframe=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Svq-tBQ6Cp2C",
        "outputId": "d85d281a-63e5-4ec0-ee24-79c2bbfd549c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - accuracy: 0.5352 - loss: 0.6921\n",
            "Epoch 2/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5621 - loss: 0.6885  \n",
            "Epoch 3/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5636 - loss: 0.6871 \n",
            "Epoch 4/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5798 - loss: 0.6858 \n",
            "Epoch 5/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5941 - loss: 0.6807 \n",
            "Epoch 6/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5995 - loss: 0.6797 \n",
            "Epoch 7/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5436 - loss: 0.6862 \n",
            "Epoch 8/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5480 - loss: 0.6868 \n",
            "Epoch 9/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5920 - loss: 0.6796 \n",
            "Epoch 10/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5986 - loss: 0.6728 \n",
            "Epoch 11/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5818 - loss: 0.6799 \n",
            "Epoch 12/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5655 - loss: 0.6838 \n",
            "Epoch 13/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6058 - loss: 0.6729 \n",
            "Epoch 14/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5506 - loss: 0.6890 \n",
            "Epoch 15/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5972 - loss: 0.6753 \n",
            "Epoch 16/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6264 - loss: 0.6650 \n",
            "Epoch 17/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5496 - loss: 0.6880 \n",
            "Epoch 18/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6102 - loss: 0.6678 \n",
            "Epoch 19/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5842 - loss: 0.6787 \n",
            "Epoch 20/20\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6221 - loss: 0.6663 \n",
            "Model training complete!\n",
            "The shape of the embedding created is:  (14559, 100)\n",
            "Embedding for jo : [[0.035978082567453384, 0.034023720771074295, -0.010251125320792198, -0.03706703335046768, 0.03645852208137512, 0.03814040869474411, -0.032651495188474655, 0.04340694844722748, -0.022448167204856873, -0.04766229912638664, 0.007423290982842445, -0.013334562070667744, -0.020125173032283783, 0.0403573140501976, -0.016479117795825005, -0.040173206478357315, 0.00011482506670290604, 0.008438716642558575, 0.02098429948091507, -0.0024819413665682077, 0.03389186039566994, -0.04018783941864967, 0.0015509941149502993, 0.00893437024205923, 0.02847316302359104, 0.02559146285057068, 0.04467951878905296, -0.03509077802300453, -0.0005794572061859071, 0.04147106781601906, -0.03863532096147537, 0.03093430958688259, -0.010221745818853378, -0.019276032224297523, 0.02945941872894764, 0.04472775757312775, -0.03789622709155083, -0.009955496527254581, -0.02688664384186268, -0.019886286929249763, 0.02376844547688961, -0.03485905006527901, -0.01855548657476902, -0.03185199573636055, 0.03873239830136299, 0.01923554018139839, -0.005343415774405003, -0.024141715839505196, -0.042091723531484604, 0.033874861896038055, -0.0300584863871336, 0.014832256361842155, -0.05103412643074989, -0.04299433156847954, -0.03516068682074547, 0.01312964502722025, -0.03945949673652649, -0.01861792802810669, 0.03703923895955086, -0.041968949139118195, -0.010105449706315994, 0.0068967584520578384, -0.01628127507865429, -0.03480513393878937, 0.015234068036079407, 0.006782152224332094, -0.006523428950458765, -0.0011694470886141062, 0.0336855985224247, -0.014241025783121586, -0.029993411153554916, -0.037328194826841354, -0.00046202167868614197, -0.01796645298600197, -0.00831114873290062, 0.027871236205101013, -0.02829008921980858, -0.04270181059837341, 0.04695793241262436, -0.004224500153213739, 0.03827366977930069, -0.04704366251826286, 0.009198143146932125, 0.010438300669193268, 0.032651688903570175, 0.023037107661366463, 0.02179243415594101, 0.03589687496423721, 0.001358314766548574, 0.028062760829925537, -0.016993919387459755, -0.013088379986584187, 0.038253698498010635, 0.04796453192830086, -0.02992090955376625, -0.028872886672616005, 0.01721976511180401, 0.03224934637546539, -0.04014730453491211, 0.027422375977039337]]\n"
          ]
        }
      ],
      "source": [
        "# sarcasm_word2vec_model = create_word2vec(X_sarcasm_train, y_sarcasm_train, sarcasm_vocab_size, 'sarcasm', sarcasm_index2word, sarcasm_word2index, epochs=20, batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGchM4DsCzSh",
        "outputId": "e1061e28-a1d1-4965-bae0-e6e0817cf87a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of the data is: X: (4200, 30) and y: (4200,)\n",
            "\n",
            "Data is ready\n"
          ]
        }
      ],
      "source": [
        "sarcasm_X_train, sarcasm_y_train = prepare_data_for_FFNN(sarcasm_train,sarcasm_word2index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "QBDDRwhgEuiJ",
        "outputId": "7f400a18-e372-4976-9091-34fbcca27482"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>403</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "0\n",
              "0    3797\n",
              "1     403\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(pd.DataFrame(sarcasm_y_train)).value_counts() #imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0vfraj9DHr8",
        "outputId": "e598bd68-aca0-4818-d167-05749613e6e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resampling data due to class imbalance...\n",
            "\n",
            "Class distribution before resampling: Counter({np.int64(0): 3797, np.int64(1): 403})\n",
            "Class distribution after resampling: Counter({np.int64(0): 403, np.int64(1): 403})\n",
            "Training the model...\n",
            "\n",
            "Epoch 1/20\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.6332 - loss: 0.6733\n",
            "Epoch 2/20\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7627 - loss: 0.5098\n",
            "Epoch 3/20\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9836 - loss: 0.1934\n",
            "Epoch 4/20\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0344\n",
            "Epoch 5/20\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0095\n",
            "Epoch 6/20\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0047\n",
            "Epoch 7/20\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0030\n",
            "Epoch 8/20\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0021\n",
            "Epoch 9/20\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0016\n",
            "Epoch 10/20\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0012\n",
            "Epoch 11/20\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.7590e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.1797e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.8104e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.7567e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.0634e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.9833e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.6353e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.0438e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7183e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3552e-04\n",
            "Model training complete!\n",
            "Model saved as sarcasm_model.keras\n"
          ]
        }
      ],
      "source": [
        "# sarcasm_model = ffnn('sarcasm', sarcasm_vocab_size, sarcasm_X_train, sarcasm_y_train,epochs=20, isclassbalanced=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCV-KGp9DP6S",
        "outputId": "39b22d3c-c32c-45b2-dfdd-46863efd8af2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model <Sequential name=sequential_6, built=True> loaded successfully!\n",
            "Shape of the data is: X: (525, 30) and y: (525,)\n",
            "\n",
            "Data is ready\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     sarcasm       0.99      0.90      0.94       474\n",
            " non_sarcasm       0.49      0.88      0.63        51\n",
            "\n",
            "    accuracy                           0.90       525\n",
            "   macro avg       0.74      0.89      0.79       525\n",
            "weighted avg       0.94      0.90      0.91       525\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate('sarcasm',sarcasm_val, sarcasm_word2index)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al9mp3uHFZrZ"
      },
      "source": [
        "## Humor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "0hxQEFMfDvv4"
      },
      "outputs": [],
      "source": [
        "humor_train, humor_val = load_and_preprocess_data('humor')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AwwQ0BPD0Pt",
        "outputId": "d45fd7e0-36ab-411a-dabf-6602498ee6c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary of 7179 created\n"
          ]
        }
      ],
      "source": [
        "humor_vocab, humor_vocab_size, humor_word2index, humor_index2word = form_vocab(humor_train,isdataframe=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q87dXblkFpN5",
        "outputId": "4065fd58-f6b3-4229-9d54-fb7f0fb94296"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary of 7179 created\n",
            "Created the target words and context words pair\n",
            "\n",
            "For word at index 4:\t rassi\n",
            "Positive samples are:\t ['like', 'jal', 'is', 'gayee', 'scindia', 'aunty', 'jyotiraditya', 'ki']\n",
            "Negative samples are:\t ['dunia', 'quality', 'bitiya', 'africans', 'manjultoons']\n",
            "\n",
            "Created the target words and context words pair using the index for training.\n",
            " \n",
            "rassi index:\t 4\n",
            "Postive samples are:\t [3, 5, 2, 6, 1, 7, 0, 8]\n",
            "Negative samples are:\t [5304, 3489, 4706, 2642, 3264]\n",
            "\n",
            "Created data for training.\n"
          ]
        }
      ],
      "source": [
        "X_humor_train, y_humor_train = create_data(data= humor_train, word2index=humor_word2index, index2word=humor_index2word,window_size = 4 , k=5, isdataframe=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf5EIbQBFwog",
        "outputId": "90165643-e9cc-472b-ae19-faef4cd21f0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 173ms/step - accuracy: 0.4902 - loss: 0.6942\n",
            "Epoch 2/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4994 - loss: 0.6936\n",
            "Epoch 3/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5438 - loss: 0.6916\n",
            "Epoch 4/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5605 - loss: 0.6908\n",
            "Epoch 5/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5584 - loss: 0.6899 \n",
            "Epoch 6/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5584 - loss: 0.6885 \n",
            "Epoch 7/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5532 - loss: 0.6887 \n",
            "Epoch 8/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6122 - loss: 0.6812 \n",
            "Epoch 9/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5523 - loss: 0.6882 \n",
            "Epoch 10/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5700 - loss: 0.6839 \n",
            "Epoch 11/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5435 - loss: 0.6854 \n",
            "Epoch 12/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6096 - loss: 0.6780 \n",
            "Epoch 13/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5909 - loss: 0.6775 \n",
            "Epoch 14/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6226 - loss: 0.6742 \n",
            "Epoch 15/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6291 - loss: 0.6737 \n",
            "Epoch 16/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5466 - loss: 0.6862 \n",
            "Epoch 17/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5488 - loss: 0.6848 \n",
            "Epoch 18/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5458 - loss: 0.6849 \n",
            "Epoch 19/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5631 - loss: 0.6789 \n",
            "Epoch 20/20\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5844 - loss: 0.6817 \n",
            "Model training complete!\n",
            "The shape of the embedding created is:  (7179, 100)\n",
            "Embedding for scindia : [[-0.02059846743941307, -0.053310882300138474, 0.006382507737725973, -0.016055801883339882, 0.04388326406478882, 0.031198149546980858, -0.02794383093714714, 0.015571433119475842, 0.01577509008347988, -0.03798600286245346, 0.008470061235129833, 0.03686543554067612, 0.03949781879782677, -0.00678663793951273, 0.008793368004262447, 0.016238141804933548, -0.0527542345225811, 0.01139686070382595, -0.028733836486935616, 0.03076220490038395, 0.040771253407001495, -0.022201744839549065, -0.011301973834633827, 0.0512651652097702, 0.007218731567263603, -0.01657758094370365, 0.035642750561237335, 0.047165174037218094, -0.021272573620080948, 0.00901257898658514, -0.007937407121062279, 0.020910099148750305, -0.002797915367409587, 0.0021450500935316086, 0.005021443124860525, -0.03407470881938934, 0.019273340702056885, 0.03475932404398918, -0.05527597293257713, 0.00674845976755023, -0.005068660248070955, 0.03267423063516617, 0.055751606822013855, 0.0517607182264328, -0.04051223769783974, -0.021481668576598167, -0.03097977116703987, -0.040015172213315964, -0.010231859982013702, -0.02881861850619316, 0.015409368090331554, -0.004856273531913757, 0.035490524023771286, -0.03749048337340355, -0.021331598982214928, 0.01317046768963337, 0.03132978454232216, 0.03382640331983566, -0.03280869498848915, 0.03433816879987717, 0.04779454693198204, 0.004318492487072945, -0.013426600024104118, -0.03475729376077652, -0.041625626385211945, 0.027140825986862183, -0.005964074283838272, -0.01796708069741726, 0.044859085232019424, -0.028829559683799744, -0.01131693460047245, -0.014065232127904892, 0.004538793116807938, 0.03137480467557907, 0.04216468334197998, -0.015029671601951122, -0.036964301019907, -0.027163924649357796, 0.0062437704764306545, -0.018047679215669632, 0.01216993760317564, 0.05537544935941696, -0.00318895629607141, -0.01531154103577137, 0.009403659962117672, 0.024241996929049492, -0.036700837314128876, 0.032044313848018646, 0.04292450100183487, 0.020979024469852448, -0.03590892255306244, -0.03188921511173248, -0.04470240697264671, 0.02361324056982994, -0.010806113481521606, 0.04000386968255043, -0.013142881914973259, 0.011497101746499538, -0.03283771127462387, 0.04793817549943924]]\n"
          ]
        }
      ],
      "source": [
        "# humor_word2vec_model = create_word2vec(X_humor_train, y_humor_train, humor_vocab_size, 'humor', humor_index2word, humor_word2index, epochs=20, batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJe8akYHF6aR",
        "outputId": "5dd38561-dd3a-44cb-8058-b57539c07f4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of the data is: X: (2360, 30) and y: (2360,)\n",
            "\n",
            "Data is ready\n"
          ]
        }
      ],
      "source": [
        "humor_X_train, humor_y_train = prepare_data_for_FFNN(humor_train,humor_word2index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "kD1AxeUJGae3",
        "outputId": "8c89f2f8-7059-4cc4-c4bb-ab416ab5fcdd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>953</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "0\n",
              "1    1407\n",
              "0     953\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(pd.DataFrame(humor_y_train)).value_counts()  #class is imbalanced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7V3ai-rGQF3",
        "outputId": "c252eed6-7a3f-4fe2-a681-45ff039d420a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resampling data due to class imbalance...\n",
            "\n",
            "Class distribution before resampling: Counter({np.int64(1): 1407, np.int64(0): 953})\n",
            "Class distribution after resampling: Counter({np.int64(0): 953, np.int64(1): 953})\n",
            "Training the model...\n",
            "\n",
            "Epoch 1/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.6224 - loss: 0.6570\n",
            "Epoch 2/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7418 - loss: 0.5388\n",
            "Epoch 3/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9699 - loss: 0.1858\n",
            "Epoch 4/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9934 - loss: 0.0279\n",
            "Epoch 5/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0069\n",
            "Epoch 6/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0039\n",
            "Epoch 7/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0018\n",
            "Epoch 8/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0012\n",
            "Epoch 9/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.9121e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 7.5037e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.6229e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.3870e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 3.2526e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 3.0322e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.3933e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 2.1026e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 1.9186e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.6672e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 1.3775e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2179e-04\n",
            "Model training complete!\n",
            "Model saved as humor_model.keras\n"
          ]
        }
      ],
      "source": [
        "# humor_ffnn_model = ffnn('humor', humor_vocab_size, humor_X_train, humor_y_train,epochs=20, isclassbalanced=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gvp3jI40GZAo",
        "outputId": "17b9020d-5462-422c-c1cf-ec6958c53161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model <Sequential name=sequential_8, built=True> loaded successfully!\n",
            "Shape of the data is: X: (295, 30) and y: (295,)\n",
            "\n",
            "Data is ready\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       humor       0.55      0.72      0.62       119\n",
            "   non_humor       0.76      0.60      0.67       176\n",
            "\n",
            "    accuracy                           0.65       295\n",
            "   macro avg       0.65      0.66      0.65       295\n",
            "weighted avg       0.67      0.65      0.65       295\n",
            "\n"
          ]
        }
      ],
      "source": [
        "evaluate('humor',humor_val, humor_word2index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "SLVgQpUNG8Y9"
      },
      "outputs": [],
      "source": [
        "# hbv = 42421\n",
        "\n",
        "# print(hbv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mmvk2Q-Hl0u"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "-fvNQ6odmlns",
        "vcXrCvxu23Wz",
        "kOfiHE7madtF"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
